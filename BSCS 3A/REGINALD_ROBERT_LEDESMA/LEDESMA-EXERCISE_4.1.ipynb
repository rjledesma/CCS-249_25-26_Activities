{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df2ac58a",
   "metadata": {},
   "source": [
    "# Exercise for Unit 4.1 Na√Øve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a39d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "documents = [\n",
    "    (\"Free money now!!!\", \"SPAM\"),\n",
    "    (\"Hi mom, how are you?\", \"HAM\"),\n",
    "    (\"Lowest price for your meds\", \"SPAM\"),\n",
    "    (\"Are we still on for dinner?\", \"HAM\"),\n",
    "    (\"Win a free iPhone today\", \"SPAM\"),\n",
    "    (\"Let's catch up tomorrow at the office\", \"HAM\"),\n",
    "    (\"Meeting at 3 PM tomorrow\", \"HAM\"),\n",
    "    (\"Get 50% off, limited time!\", \"SPAM\"),\n",
    "    (\"Team meeting in the office\", \"HAM\"),\n",
    "    (\"Click here for prizes!\", \"SPAM\"),\n",
    "    (\"Can you send the report?\", \"HAM\")\n",
    "]\n",
    "\n",
    "#text preprocess\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z0-9\\s]', '', text)\n",
    "    return text.split()\n",
    "\n",
    "#build vocab\n",
    "def build_vocab(documents):\n",
    "    vocab = set()\n",
    "    for text, _ in documents:\n",
    "        words = preprocess(text)\n",
    "        vocab.update(words)\n",
    "    return list(vocab)\n",
    "\n",
    "def bag_of_words(documents, vocab):\n",
    "    word_counts = {\n",
    "        \"HAM\": defaultdict(int),\n",
    "        \"SPAM\": defaultdict(int),\n",
    "    }\n",
    "    class_counts = {\"HAM\": 0, \"SPAM\": 0}\n",
    "\n",
    "    for text, label in documents:\n",
    "        class_counts[label] += 1\n",
    "        words = preprocess(text)\n",
    "        for word in words:\n",
    "            word_counts[label][word] += 1\n",
    "\n",
    "    return word_counts, class_counts\n",
    "\n",
    "#naive bays train\n",
    "def train_naive_bays(documents):\n",
    "    vocab = build_vocab(documents)\n",
    "    word_counts, class_counts = bag_of_words(documents, vocab)\n",
    "\n",
    "    total_docs = len(documents)\n",
    "    priors = {\n",
    "        c: class_counts[c] / total_docs\n",
    "        for c in class_counts\n",
    "    }\n",
    "\n",
    "    likelihoods = {\"HAM\": {}, \"SPAM\": {}}\n",
    "    vocab_size = len (vocab)\n",
    "\n",
    "    for c in [\"HAM\", \"SPAM\"]:\n",
    "        total_words = sum(word_counts[c].values())\n",
    "        for word in vocab:\n",
    "            likelihoods[c][word] = (\n",
    "                word_counts[c][word] + 1\n",
    "            ) / (total_words + vocab_size)\n",
    "\n",
    "    return priors, likelihoods, vocab\n",
    "    \n",
    "def predict(text, priors, likelihoods, vocab):\n",
    "    words = preprocess(text)\n",
    "    scores = {}\n",
    "\n",
    "    for c in [\"HAM\", \"SPAM\"]:\n",
    "        score = priors[c]\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                score *= likelihoods[c][word]\n",
    "            scores[c] = score\n",
    "    \n",
    "    return max(scores, key=scores.get)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ef05491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Priors: \n",
      "{'HAM': 0.5454545454545454, 'SPAM': 0.45454545454545453}\n",
      "\n",
      "Sentence: Limited offer, click here!\n",
      "\n",
      "Predicted Class: SPAM\n",
      "Likelihoods: {'HAM': {'lets': 0.025974025974025976, '50': 0.012987012987012988, 'click': 0.012987012987012988, 'now': 0.012987012987012988, 'the': 0.05194805194805195, 'iphone': 0.012987012987012988, 'tomorrow': 0.03896103896103896, 'report': 0.025974025974025976, 'pm': 0.025974025974025976, 'can': 0.025974025974025976, 'money': 0.012987012987012988, 'price': 0.012987012987012988, 'catch': 0.025974025974025976, 'meeting': 0.03896103896103896, 'limited': 0.012987012987012988, 'off': 0.012987012987012988, 'free': 0.012987012987012988, 'today': 0.012987012987012988, 'lowest': 0.012987012987012988, 'office': 0.03896103896103896, 'for': 0.025974025974025976, 'mom': 0.025974025974025976, 'how': 0.025974025974025976, 'win': 0.012987012987012988, 'you': 0.03896103896103896, 'we': 0.025974025974025976, 'dinner': 0.025974025974025976, 'hi': 0.025974025974025976, 'your': 0.012987012987012988, 'at': 0.03896103896103896, 'get': 0.012987012987012988, '3': 0.025974025974025976, 'on': 0.025974025974025976, 'meds': 0.012987012987012988, 'send': 0.025974025974025976, 'in': 0.025974025974025976, 'prizes': 0.012987012987012988, 'team': 0.025974025974025976, 'up': 0.025974025974025976, 'still': 0.025974025974025976, 'a': 0.012987012987012988, 'here': 0.012987012987012988, 'are': 0.03896103896103896, 'time': 0.012987012987012988}, 'SPAM': {'lets': 0.015151515151515152, '50': 0.030303030303030304, 'click': 0.030303030303030304, 'now': 0.030303030303030304, 'the': 0.015151515151515152, 'iphone': 0.030303030303030304, 'tomorrow': 0.015151515151515152, 'report': 0.015151515151515152, 'pm': 0.015151515151515152, 'can': 0.015151515151515152, 'money': 0.030303030303030304, 'price': 0.030303030303030304, 'catch': 0.015151515151515152, 'meeting': 0.015151515151515152, 'limited': 0.030303030303030304, 'off': 0.030303030303030304, 'free': 0.045454545454545456, 'today': 0.030303030303030304, 'lowest': 0.030303030303030304, 'office': 0.015151515151515152, 'for': 0.045454545454545456, 'mom': 0.015151515151515152, 'how': 0.015151515151515152, 'win': 0.030303030303030304, 'you': 0.015151515151515152, 'we': 0.015151515151515152, 'dinner': 0.015151515151515152, 'hi': 0.015151515151515152, 'your': 0.030303030303030304, 'at': 0.015151515151515152, 'get': 0.030303030303030304, '3': 0.015151515151515152, 'on': 0.015151515151515152, 'meds': 0.030303030303030304, 'send': 0.015151515151515152, 'in': 0.015151515151515152, 'prizes': 0.030303030303030304, 'team': 0.015151515151515152, 'up': 0.015151515151515152, 'still': 0.015151515151515152, 'a': 0.030303030303030304, 'here': 0.030303030303030304, 'are': 0.015151515151515152, 'time': 0.030303030303030304}}\n",
      "\n",
      "Sentence: Meeting at 2 PM with the manager.\n",
      "\n",
      "Predicted Class: HAM\n",
      "Likelihoods: {'HAM': {'lets': 0.025974025974025976, '50': 0.012987012987012988, 'click': 0.012987012987012988, 'now': 0.012987012987012988, 'the': 0.05194805194805195, 'iphone': 0.012987012987012988, 'tomorrow': 0.03896103896103896, 'report': 0.025974025974025976, 'pm': 0.025974025974025976, 'can': 0.025974025974025976, 'money': 0.012987012987012988, 'price': 0.012987012987012988, 'catch': 0.025974025974025976, 'meeting': 0.03896103896103896, 'limited': 0.012987012987012988, 'off': 0.012987012987012988, 'free': 0.012987012987012988, 'today': 0.012987012987012988, 'lowest': 0.012987012987012988, 'office': 0.03896103896103896, 'for': 0.025974025974025976, 'mom': 0.025974025974025976, 'how': 0.025974025974025976, 'win': 0.012987012987012988, 'you': 0.03896103896103896, 'we': 0.025974025974025976, 'dinner': 0.025974025974025976, 'hi': 0.025974025974025976, 'your': 0.012987012987012988, 'at': 0.03896103896103896, 'get': 0.012987012987012988, '3': 0.025974025974025976, 'on': 0.025974025974025976, 'meds': 0.012987012987012988, 'send': 0.025974025974025976, 'in': 0.025974025974025976, 'prizes': 0.012987012987012988, 'team': 0.025974025974025976, 'up': 0.025974025974025976, 'still': 0.025974025974025976, 'a': 0.012987012987012988, 'here': 0.012987012987012988, 'are': 0.03896103896103896, 'time': 0.012987012987012988}, 'SPAM': {'lets': 0.015151515151515152, '50': 0.030303030303030304, 'click': 0.030303030303030304, 'now': 0.030303030303030304, 'the': 0.015151515151515152, 'iphone': 0.030303030303030304, 'tomorrow': 0.015151515151515152, 'report': 0.015151515151515152, 'pm': 0.015151515151515152, 'can': 0.015151515151515152, 'money': 0.030303030303030304, 'price': 0.030303030303030304, 'catch': 0.015151515151515152, 'meeting': 0.015151515151515152, 'limited': 0.030303030303030304, 'off': 0.030303030303030304, 'free': 0.045454545454545456, 'today': 0.030303030303030304, 'lowest': 0.030303030303030304, 'office': 0.015151515151515152, 'for': 0.045454545454545456, 'mom': 0.015151515151515152, 'how': 0.015151515151515152, 'win': 0.030303030303030304, 'you': 0.015151515151515152, 'we': 0.015151515151515152, 'dinner': 0.015151515151515152, 'hi': 0.015151515151515152, 'your': 0.030303030303030304, 'at': 0.015151515151515152, 'get': 0.030303030303030304, '3': 0.015151515151515152, 'on': 0.015151515151515152, 'meds': 0.030303030303030304, 'send': 0.015151515151515152, 'in': 0.015151515151515152, 'prizes': 0.030303030303030304, 'team': 0.015151515151515152, 'up': 0.015151515151515152, 'still': 0.015151515151515152, 'a': 0.030303030303030304, 'here': 0.030303030303030304, 'are': 0.015151515151515152, 'time': 0.030303030303030304}}\n"
     ]
    }
   ],
   "source": [
    "priors, likelihoods, vocab = train_naive_bays(documents)\n",
    "\n",
    "print(\"Priors: \")\n",
    "print(priors)\n",
    "\n",
    "test_sentences = [\n",
    "    \"Limited offer, click here!\",\n",
    "    \"Meeting at 2 PM with the manager.\"\n",
    "]\n",
    "\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    prediction = predict(sentence, priors, likelihoods, vocab)\n",
    "    print(f\"\\nSentence: {sentence}\\n\")\n",
    "    print(\"Predicted Class:\", prediction)\n",
    "    print(f\"Likelihoods: {likelihoods}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbf3744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'HAM': defaultdict(<class 'int'>, {'hi': 1, 'mom': 1, 'how': 1, 'are': 2, 'you': 2, 'we': 1, 'still': 1, 'on': 1, 'for': 1, 'dinner': 1, 'lets': 1, 'catch': 1, 'up': 1, 'tomorrow': 2, 'at': 2, 'the': 3, 'office': 2, 'meeting': 2, '3': 1, 'pm': 1, 'team': 1, 'in': 1, 'can': 1, 'send': 1, 'report': 1}), 'SPAM': defaultdict(<class 'int'>, {'free': 2, 'money': 1, 'now': 1, 'lowest': 1, 'price': 1, 'for': 2, 'your': 1, 'meds': 1, 'win': 1, 'a': 1, 'iphone': 1, 'today': 1, 'get': 1, '50': 1, 'off': 1, 'limited': 1, 'time': 1, 'click': 1, 'here': 1, 'prizes': 1})}, {'HAM': 6, 'SPAM': 5})\n",
      "({'HAM': 0.5454545454545454, 'SPAM': 0.45454545454545453}, {'HAM': {'lets': 0.025974025974025976, '50': 0.012987012987012988, 'click': 0.012987012987012988, 'now': 0.012987012987012988, 'the': 0.05194805194805195, 'iphone': 0.012987012987012988, 'tomorrow': 0.03896103896103896, 'report': 0.025974025974025976, 'pm': 0.025974025974025976, 'can': 0.025974025974025976, 'money': 0.012987012987012988, 'price': 0.012987012987012988, 'catch': 0.025974025974025976, 'meeting': 0.03896103896103896, 'limited': 0.012987012987012988, 'off': 0.012987012987012988, 'free': 0.012987012987012988, 'today': 0.012987012987012988, 'lowest': 0.012987012987012988, 'office': 0.03896103896103896, 'for': 0.025974025974025976, 'mom': 0.025974025974025976, 'how': 0.025974025974025976, 'win': 0.012987012987012988, 'you': 0.03896103896103896, 'we': 0.025974025974025976, 'dinner': 0.025974025974025976, 'hi': 0.025974025974025976, 'your': 0.012987012987012988, 'at': 0.03896103896103896, 'get': 0.012987012987012988, '3': 0.025974025974025976, 'on': 0.025974025974025976, 'meds': 0.012987012987012988, 'send': 0.025974025974025976, 'in': 0.025974025974025976, 'prizes': 0.012987012987012988, 'team': 0.025974025974025976, 'up': 0.025974025974025976, 'still': 0.025974025974025976, 'a': 0.012987012987012988, 'here': 0.012987012987012988, 'are': 0.03896103896103896, 'time': 0.012987012987012988}, 'SPAM': {'lets': 0.015151515151515152, '50': 0.030303030303030304, 'click': 0.030303030303030304, 'now': 0.030303030303030304, 'the': 0.015151515151515152, 'iphone': 0.030303030303030304, 'tomorrow': 0.015151515151515152, 'report': 0.015151515151515152, 'pm': 0.015151515151515152, 'can': 0.015151515151515152, 'money': 0.030303030303030304, 'price': 0.030303030303030304, 'catch': 0.015151515151515152, 'meeting': 0.015151515151515152, 'limited': 0.030303030303030304, 'off': 0.030303030303030304, 'free': 0.045454545454545456, 'today': 0.030303030303030304, 'lowest': 0.030303030303030304, 'office': 0.015151515151515152, 'for': 0.045454545454545456, 'mom': 0.015151515151515152, 'how': 0.015151515151515152, 'win': 0.030303030303030304, 'you': 0.015151515151515152, 'we': 0.015151515151515152, 'dinner': 0.015151515151515152, 'hi': 0.015151515151515152, 'your': 0.030303030303030304, 'at': 0.015151515151515152, 'get': 0.030303030303030304, '3': 0.015151515151515152, 'on': 0.015151515151515152, 'meds': 0.030303030303030304, 'send': 0.015151515151515152, 'in': 0.015151515151515152, 'prizes': 0.030303030303030304, 'team': 0.015151515151515152, 'up': 0.015151515151515152, 'still': 0.015151515151515152, 'a': 0.030303030303030304, 'here': 0.030303030303030304, 'are': 0.015151515151515152, 'time': 0.030303030303030304}}, ['lets', '50', 'click', 'now', 'the', 'iphone', 'tomorrow', 'report', 'pm', 'can', 'money', 'price', 'catch', 'meeting', 'limited', 'off', 'free', 'today', 'lowest', 'office', 'for', 'mom', 'how', 'win', 'you', 'we', 'dinner', 'hi', 'your', 'at', 'get', '3', 'on', 'meds', 'send', 'in', 'prizes', 'team', 'up', 'still', 'a', 'here', 'are', 'time'])\n"
     ]
    }
   ],
   "source": [
    "# vocab = build_vocab(documents)\n",
    "# print(bag_of_words(documents, vocab))\n",
    "# print(train_naive_bays(documents))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531b2df0",
   "metadata": {},
   "source": [
    "# Part 2 Using Scikit-Learn MultinomialDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76aa04e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Limited offer, click here!\n",
      "Predicted Class: SPAM\n",
      "\n",
      "Sentence: Meeting at 2 PM with the manager.\n",
      "Predicted Class: HAM\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "texts = [\n",
    "    \"Free money now!!!\",\n",
    "    \"Hi mom, how are you?\",\n",
    "    \"Lowest price for your meds\",\n",
    "    \"Are we still on for dinner?\",\n",
    "    \"Win a free iPhone today\",\n",
    "    \"Let's catch up tomorrow at the office\",\n",
    "    \"Meeting at 3 PM tomorrow\",\n",
    "    \"Get 50% off, limited time!\",\n",
    "    \"Team meeting in the office\",\n",
    "    \"Click here for prizes!\",\n",
    "    \"Can you send the report?\"\n",
    "]\n",
    "\n",
    "labels = [\n",
    "    \"SPAM\", \"HAM\", \"SPAM\", \"HAM\", \"SPAM\",\n",
    "    \"HAM\", \"HAM\", \"SPAM\", \"HAM\", \"SPAM\", \"HAM\"\n",
    "]\n",
    "\n",
    "#convert text to feature vectors\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(texts)\n",
    "\n",
    "#model\n",
    "model = MultinomialNB()\n",
    "model.fit(X, labels)\n",
    "\n",
    "test_sentences = [\n",
    "    \"Limited offer, click here!\",\n",
    "    \"Meeting at 2 PM with the manager.\"\n",
    "]\n",
    "\n",
    "X_test = vectorizer.transform(test_sentences)\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "for sentence, pred in zip(test_sentences, predictions):\n",
    "    print(f\"\\nSentence: {sentence}\")\n",
    "    print(\"Predicted Class:\", pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
